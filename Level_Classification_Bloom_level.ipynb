{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for predicting Second Language Adquisiton\n",
    "\n",
    "We start by loading the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.18.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.virtualenvs/huggingface/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "from fastai.data.all import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.metrics import accuracy, F1Score\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "from blurr.text.data.core import *\n",
    "from blurr.text.modeling.core import *\n",
    "from blurr.text.utils import NLP\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('perplejidad/datasets/train_train_set.csv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('perplejidad/datasets/validation_train_set.csv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33684, 3743)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df),len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_valid']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['is_valid']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_df = pd.concat([train_df,valid_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the indexes for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, valid_idxs = L(range(len(train_valid_df[train_valid_df.is_valid==False]))), L(range(len(train_valid_df[train_valid_df.is_valid==False]), len(train_valid_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define the model. In this case, we use a predefined model called Roberta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1', 'A2', 'B1', 'B2', 'C1'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_valid_df.Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bloom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-71418428cd45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpretrained_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bigscience/bloom-1b3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m hf_arch, hf_config, hf_tokenizer,hf_model = NLP.get_hf_objects(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpretrained_model_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_cls\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"num_labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/blurr/text/utils.py\u001b[0m in \u001b[0;36mget_hf_objects\u001b[0;34m(self, pretrained_model_name_or_path, model_cls, config, tokenizer_cls, config_kwargs, tokenizer_kwargs, model_kwargs, cache_dir)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# tokenizer (gpt2, roberta, bart (and maybe others) tokenizers require a prefix space)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type_to_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bloom'"
     ]
    }
   ],
   "source": [
    "model_cls = AutoModelForSequenceClassification\n",
    "pretrained_model_name = \"bigscience/bloom-1b3\"\n",
    "hf_arch, hf_config, hf_tokenizer,hf_model = NLP.get_hf_objects(\n",
    "    pretrained_model_name,model_cls= model_cls, config_kwargs={\"num_labels\": 5}\n",
    ")\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer),type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_kwargs = {\"bs\": 64, \"val_bs\": 64}\n",
    "learn_kwargs = {\"metrics\": [accuracy]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bb8127b47d443d872a1ba9dd565d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'bloom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-35c09cf593a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdblock_splitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIndexSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdl_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlearner_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearn_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/blurr/text/modeling/core.py\u001b[0m in \u001b[0;36mfrom_data\u001b[0;34m(cls, data, pretrained_model_name_or_path, text_attr, label_attr, n_labels, dblock_splitter, dl_kwargs, learner_kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# get our hf objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         hf_arch, hf_config, hf_tokenizer, hf_model = NLP.get_hf_objects(\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"num_labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/blurr/text/utils.py\u001b[0m in \u001b[0;36mget_hf_objects\u001b[0;34m(self, pretrained_model_name_or_path, model_cls, config, tokenizer_cls, config_kwargs, tokenizer_kwargs, model_kwargs, cache_dir)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# tokenizer (gpt2, roberta, bart (and maybe others) tokenizers require a prefix space)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_content\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_type_to_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bloom'"
     ]
    }
   ],
   "source": [
    "learn = BlearnerForSequenceClassification.from_data(\n",
    "    train_valid_df,\n",
    "    \"bigscience/bloom-1b3\",\n",
    "    text_attr=\"Sentence\",\n",
    "    label_attr=\"Level\",\n",
    "    dblock_splitter=IndexSplitter(valid_idxs),\n",
    "    dl_kwargs=dl_kwargs,\n",
    "    learner_kwargs=learn_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aquí es mi número de teléfono + : + 18270918681 +. + por _ favor teléfono + : + 18270918681 +. + por _ favor teléfono + : + 18270918681 +. + por _ favor teléfono + : + 18270918681 +. + por _ favor teléfono + : + 18270918681 +. + por _ favor, puede llamar me por eso.</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>visitamos a muchos lugares muy interesantes como las mezquitas sultan _ ayub y achakirine, topkapi etc... mi lugar preferido fue la mezquita _ de _ sultan _ ayub : sentí cosas que no puedo describir te.</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regi, solamente llegaré a casa por volta de la una _ y _ media por que la película retrasó mucho para empezar, y entonces, solamente terminará a la una _ hora _ de _ la _ mañana, por _ favor, no te preocupes.</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>durante el fin de semana pasado, en _ medio _ de el descanso de 5 dias debido _ a la celebracion de el dia _ de _ accion _ de _ gracias, fuimos un grupo de 11 personas a la casa de mis padres en wisconsin.</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lo que me gustó mas fueran las visitas en la parte vieja de la ciudad, la descoberta de la arquitectura, la italiana, las pasajens pedestres de una rua para una otra, atraversando las casas ( las</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, trunc_at=500, max_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.953426</td>\n",
       "      <td>0.901619</td>\n",
       "      <td>0.651082</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.695642</td>\n",
       "      <td>0.676943</td>\n",
       "      <td>0.741384</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.577810</td>\n",
       "      <td>0.628538</td>\n",
       "      <td>0.762757</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.486175</td>\n",
       "      <td>0.627879</td>\n",
       "      <td>0.772108</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.345778</td>\n",
       "      <td>0.660044</td>\n",
       "      <td>0.777718</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.252270</td>\n",
       "      <td>0.787121</td>\n",
       "      <td>0.773177</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.134410</td>\n",
       "      <td>0.919224</td>\n",
       "      <td>0.778787</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.069845</td>\n",
       "      <td>1.037823</td>\n",
       "      <td>0.777184</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077579</td>\n",
       "      <td>1.130261</td>\n",
       "      <td>0.782260</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.045114</td>\n",
       "      <td>1.201705</td>\n",
       "      <td>0.781726</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>1.218270</td>\n",
       "      <td>0.781192</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(10,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('bert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/bert-new.pth')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save('bert-new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('perplejidad/datasets/test_set.csv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['is_valid']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33684"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = pd.concat([train_df,test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, test_idxs = L(range(len(train_test_df[train_test_df.is_valid==False]))), L(range(len(train_test_df[train_test_df.is_valid==False]), len(train_test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnTest = BlearnerForSequenceClassification.from_data(\n",
    "    train_test_df,\n",
    "    \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
    "    text_attr=\"Sentence\",\n",
    "    label_attr=\"Level\",\n",
    "    dblock_splitter=IndexSplitter(test_idxs),\n",
    "    dl_kwargs=dl_kwargs,\n",
    "    learner_kwargs=learn_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blurr.text.modeling.core.BlearnerForSequenceClassification at 0x7f2a03e0add8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnTest.load('bert-new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [1.2462292909622192,0.781660795211792]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnTest.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds,gt=learnTest.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(gt, np.argmax(preds,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=learnTest.dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2abc2b1b70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learnTest.hf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs):\n",
    "    return model(inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id):\n",
    "\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_forward(inputs):\n",
    "    preds = predict(inputs)\n",
    "    return torch.softmax(preds, dim = 1)[0][1].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import visualization as viz\n",
    "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(custom_forward, model.bert.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Dos hijas viven con él y la otra en Marseille .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n",
    "token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "indices = input_ids[0].detach().tolist()\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.9123, -0.3355, -7.6495, -4.1155, -4.4623]], device='cuda:2',\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check predict output\n",
    "predict(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.4899e-07], device='cuda:2', grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check output of custom_forward\n",
    "custom_forward(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Cannot choose target column with output shape torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f866542246d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0minternal_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mreturn_convergence_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                     target=0)\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/captum/attr/_core/layer/layer_integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0minternal_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternal_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0mreturn_convergence_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         )\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             )\n\u001b[1;32m    285\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/captum/attr/_utils/batching.py\u001b[0m in \u001b[0;36m_batch_attribution\u001b[0;34m(attr_method, num_examples, internal_batch_size, n_steps, include_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_alphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         current_attr = attr_method._attribute(\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_sizes_and_alphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36m_attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaled_features_tpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mtarget_ind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_additional_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         )\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/captum/attr/_core/layer/layer_integrated_gradients.py\u001b[0m in \u001b[0;36mgradient_func\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     output = _run_forward(\n\u001b[0;32m--> 466\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m                     )\n\u001b[1;32m    468\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     )\n\u001b[0;32m--> 441\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_select_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_select_targets\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_verify_select_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/huggingface/lib/python3.6/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_verify_select_column\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    497\u001b[0m     assert (\n\u001b[1;32m    498\u001b[0m         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m     ), \"Cannot choose target column with output shape %r.\" % (output.shape,)\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Cannot choose target column with output shape torch.Size([1])."
     ]
    }
   ],
   "source": [
    "attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                                    baselines=ref_input_ids,\n",
    "                                    n_steps=700,\n",
    "                                    internal_batch_size=3,\n",
    "                                    return_convergence_delta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions_sum = summarize_attributions(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = predict(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.9123, -0.3355, -7.6495, -4.1155, -4.4623]], device='cuda:2',\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing couple samples in an array for visualization purposes\n",
    "score_vis = viz.VisualizationDataRecord(attributions_sum,\n",
    "                                        torch.softmax(score, dim = 1)[0][1],\n",
    "                                        torch.argmax(torch.softmax(score, dim = 0)[0]),\n",
    "                                        1,\n",
    "                                        text,\n",
    "                                        attributions_sum.sum(),       \n",
    "                                        all_tokens,\n",
    "                                        delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Visualization For Score \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Dos hijas viven con él y la otra en Marseille .</b></text></td><td><text style=\"padding-right:2em\"><b>-0.29</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dos                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hijas                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> viven                    </font></mark><mark style=\"background-color: hsl(120, 75%, 63%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> con                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> él                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> y                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> la                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> otra                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> en                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mars                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ei                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##lle                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.00)</b></text></td><td><text style=\"padding-right:2em\"><b>Dos hijas viven con él y la otra en Marseille .</b></text></td><td><text style=\"padding-right:2em\"><b>-0.29</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> dos                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hijas                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> viven                    </font></mark><mark style=\"background-color: hsl(120, 75%, 63%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> con                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> él                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> y                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> la                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> otra                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> en                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mars                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ei                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##lle                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\033[1m', 'Visualization For Score', '\\033[0m')\n",
    "viz.visualize_text([score_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
